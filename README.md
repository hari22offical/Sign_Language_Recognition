# Sign_Language_Recognition

<!DOCTYPE html>
<html>
  <head>
    <img src="https://miro.medium.com/v2/resize:fit:1400/0*Iv-GIxB6KwJpZPaQ" alt="Safety Gear" width="1000" height="475" title=" Sign_Language_Recognition" align="center" style="margin-top: 10px; border: 1px solid #ccc;">
  </head>
  <body>
    <p><b>‚Ü™ PROBLEM STATEMENT:</b></p>
    <p>&emsp;&emsp;&emsp;Sign Language is a form of communication used primarily by people hard of hearing or deaf. This type of gesture-based language allows people to convey ideas and thoughts easily overcoming the barriers caused by difficulties from hearing issues.

A major issue with this convenient form of communication is the lack of knowledge of the language for the vast majority of the global population. Just as any other language, learning Sign Language takes much time and effort, discouraging to from being learned by the larger population.

However, an evident solution to this issue is present in the world of Machine Learning and Image Detection. Implementing predictive model technology to automatically classify Sign Language symbols can be used to create a form of real-time captioning for virtual conferences like Zoom meetings and other such things. This would greatly increase access of such services to those with hearing impairments as it would go hand-in-hand with voice-based captioning, creating a two-way communication system online for people with hearing issues.

</p>
    <br>
    <p><b>üéØ OBJECTIVE:</b></p>
    <p>&emsp;&emsp;&emsp;Communication is one of the basic requirement for survival in society. Deaf and dumb people communicate among themselves using sign language but normal people find it difficult to understand their language. Extensive work has beendone on American sign language recognition but Indian
sign language differs significantly from American sign.</p>
    <br>

  <div>
    <p><b>üí° SOLUTION:</b></p>
    <p>&emsp;&emsp;&emsp;<h2>A.Image Capture:</h2>
This is the first stepinsignrecognition.Camera interfacing isa verycriticalpart.Webcamera isused to capture the hand gesture. Now web camera is also inbuiltinlaptops&one can use external cameraforinterfacing.Butcapturedimagesneed to be in high definition. So selection of good webcam & its interfacing is an importanttask of this method.
<h2>B. Image Preprocessing:</h2>
Image preprocessing contains cropping, filtering, brightness &contrast adjustment & many more. To do such process Image enhancement, Image cropping & Image
Segmentation methods are used. Captured Images are inithe form of iRGB. So the first step is to convert RGB images to binary images then cropping of image is to be done so that unwanted part of i images can be removed. And now enhancement can be done in certain selected area. In Image segmentation, Edge detection method is used which can detectthe boundary of cropped images which is furtherused for feature extraction method.
      
<h2>C. Feature Extraction:</h2>
Feature extractioni is avery useful step to create the databaseofsignrecognition.Tocharacterizethediversevisual principles of letters in manual alphabet efficiently and effectively, both the global visual features and the local visual features are extracted for letter image similarity characterization There are mainly two types of feature extraction method involved in sign recognition, First is Contour-based shape representation iand descriptioni methods &I another is Region-based shape representation and description methods. Among those depending on application methods are selected.
</p>
    </div>

   
 
  <hr>
    <div>
    
   <p><b>‚ôªÔ∏è SYSTEM WORKFLOW:</b></p>
   
![System Workflow](https://user-images.githubusercontent.com/108861190/234074536-4daa420c-8e44-4066-9141-e03402cafd9b.png)




  </body>
